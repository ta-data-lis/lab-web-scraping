{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended content.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit the urls below and take a look at their source code through Chrome DevTools. You'll need to identify the html tags, special class names, etc used in the html content you are expected to extract.\n",
    "\n",
    "**Resources**:\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide)\n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are already imported for you. If you prefer to use additional libraries feel free to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import requests\n",
    "\n",
    "html = requests.get(url).content\n",
    "#html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html, \"lxml\")  \n",
    "#soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "developers = soup.find_all('h1',attrs = {'class':\"h3 lh-condensed\"})\n",
    "\n",
    "#developers = soup.find_all('div',attrs = {'class':\"col-md-6\"})\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1 class=\"h3 lh-condensed\"><a href=\"/kripken\">Alon Zakai</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/seanmonstar\">Sean McArthur</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/carllerche\">Carl Lerche</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/alanshaw\">Alan Shaw</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/michalsnik\">Michał Sajnóg</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/dpgaspar\">Daniel Vaz Gaspar</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/LucioFranco\">Lucio Franco</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/rimusz\">Rimas Mocevicius</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/rnystrom\">Ryan Nystrom</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/tsenart\">Tomás Senart</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/maartenbreddels\">Maarten Breddels</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/kataras\">Gerasimos (Makis) Maropoulos</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/jquense\">Jason Quense</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/mcollina\">Matteo Collina</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/normanmaurer\">Norman Maurer</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/EddyVerbruggen\">Eddy Verbruggen</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/jez\">Jake Zimmerman</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/jenssegers\">Jens Segers</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/freekmurze\">Freek Van der Herten</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/wkentaro\">Kentaro Wada</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/torkelo\">Torkel Ödegaard</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/nex3\">Natalie Weizenbaum</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/tiangolo\">Sebastián Ramírez</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/denysdovhan\">Denys Dovhan</a></h1>,\n",
       " <h1 class=\"h3 lh-condensed\"><a href=\"/ktsn\">katashin</a></h1>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "developers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alon Zakai']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "developers_name_lst = [developers[0].text.replace('\\n', ' ').strip(' ')]\n",
    "developers_name_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub.\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_rep = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "html_rep = requests.get(url_rep).content\n",
    "#html_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautiful soup\n",
    "\n",
    "soup_rep = BeautifulSoup(html_rep, \"lxml\")  \n",
    "#soup_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = soup_rep.find_all('h1',attrs = {'class':\"h3 lh-condensed\"})\n",
    "#rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['microsoft / nlp',\n",
       " 'deepfakes / faceswap',\n",
       " 'eriklindernoren / ML-From-Scratch',\n",
       " 'openai / baselines',\n",
       " 'google / brain-tokyo-workshop',\n",
       " 'public-apis / public-apis',\n",
       " 'openai / gym',\n",
       " 'ansible / ansible',\n",
       " 'zalandoresearch / flair',\n",
       " 'Kr1s77 / awesome-python-login-model',\n",
       " 'fendouai / PyTorchDocs',\n",
       " 'pennersr / django-allauth',\n",
       " 'pi-hole / docker-pi-hole',\n",
       " 'dmlc / tvm',\n",
       " 'google-research / google-research',\n",
       " 'google-research / football',\n",
       " 'huggingface / pytorch-transformers',\n",
       " 'apache / airflow',\n",
       " 'techwithtim / NEAT-Flappy-Bird',\n",
       " 'apache / incubator-mxnet',\n",
       " 'saltstack / salt',\n",
       " 'kovidgoyal / calibre',\n",
       " 'STVIR / pysot',\n",
       " 'eeshashetty / InvisibilityCloak',\n",
       " 'tensorflow / addons']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_lst = [r.text.replace('\\n', ' ').strip(' ') for r in rep[0:]]\n",
    "rep_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_disney = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "html_disney = requests.get(url_disney).content\n",
    "#html_disney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautiful soup\n",
    "\n",
    "soup_disney = BeautifulSoup(html_disney, \"lxml\")  \n",
    "#soup_disney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_disney = soup_disney.find_all('a',attrs = {'class':\"image\"})\n",
    "#image_disney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/wiki/File:Walt_Disney_1946.JPG',\n",
       " '/wiki/File:Walt_Disney_1942_signature.svg',\n",
       " '/wiki/File:Walt_Disney_envelope_ca._1921.jpg',\n",
       " '/wiki/File:Trolley_Troubles_poster.jpg',\n",
       " '/wiki/File:Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg',\n",
       " '/wiki/File:Steamboat-willie.jpg',\n",
       " '/wiki/File:Walt_Disney_1935.jpg',\n",
       " '/wiki/File:Walt_Disney_Snow_white_1937_trailer_screenshot_(13).jpg',\n",
       " '/wiki/File:Disney_drawing_goofy.jpg',\n",
       " '/wiki/File:DisneySchiphol1951.jpg',\n",
       " '/wiki/File:WaltDisneyplansDisneylandDec1954.jpg',\n",
       " '/wiki/File:Walt_disney_portrait_right.jpg',\n",
       " '/wiki/File:Walt_Disney_Grave.JPG',\n",
       " '/wiki/File:Roy_O._Disney_with_Company_at_Press_Conference.jpg',\n",
       " '/wiki/File:Disney_Display_Case.JPG',\n",
       " '/wiki/File:Disney1968.jpg',\n",
       " '/wiki/File:Animation_disc.svg',\n",
       " '/wiki/File:P_vip.svg',\n",
       " '/wiki/File:Magic_Kingdom_castle.jpg',\n",
       " '/wiki/File:Video-x-generic.svg',\n",
       " '/wiki/File:Flag_of_Los_Angeles_County,_California.svg',\n",
       " '/wiki/File:USA_flag_on_television.svg']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_disney_lst = [i.get('href').replace('\\n', ' ').strip(' ') for i in image_disney[0:]]\n",
    "\n",
    "image_disney_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_python ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "html_python = requests.get(url_python).content\n",
    "html_python\n",
    "\n",
    "# Beautiful soup\n",
    "soup_python = BeautifulSoup(html_python, \"lxml\")  \n",
    "#soup_python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "links_python = soup_python.findAll('a', attrs = {'href' : re.compile('http')})\n",
    "\n",
    "links_python_lst = [link.get('href') for link in links_python]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wiktionary.org/wiki/Python',\n",
       " 'https://en.wiktionary.org/wiki/python',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Python&namespace=0',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&oldid=912426772',\n",
       " 'https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q747452',\n",
       " 'https://commons.wikimedia.org/wiki/Category:Python',\n",
       " 'https://af.wikipedia.org/wiki/Python',\n",
       " 'https://als.wikipedia.org/wiki/Python',\n",
       " 'https://az.wikipedia.org/wiki/Python',\n",
       " 'https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A6%BE%E0%A6%87%E0%A6%A5%E0%A6%A8_(%E0%A6%A6%E0%A7%8D%E0%A6%AC%E0%A7%8D%E0%A6%AF%E0%A6%B0%E0%A7%8D%E0%A6%A5%E0%A6%A4%E0%A6%BE_%E0%A6%A8%E0%A6%BF%E0%A6%B0%E0%A6%B8%E0%A6%A8)',\n",
       " 'https://be.wikipedia.org/wiki/Python',\n",
       " 'https://bg.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%BF%D0%BE%D1%8F%D1%81%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5)',\n",
       " 'https://cs.wikipedia.org/wiki/Python_(rozcestn%C3%ADk)',\n",
       " 'https://da.wikipedia.org/wiki/Python',\n",
       " 'https://de.wikipedia.org/wiki/Python',\n",
       " 'https://eo.wikipedia.org/wiki/Pitono_(apartigilo)',\n",
       " 'https://eu.wikipedia.org/wiki/Python_(argipena)',\n",
       " 'https://fa.wikipedia.org/wiki/%D9%BE%D8%A7%DB%8C%D8%AA%D9%88%D9%86',\n",
       " 'https://fr.wikipedia.org/wiki/Python',\n",
       " 'https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%84%A0',\n",
       " 'https://hr.wikipedia.org/wiki/Python_(razdvojba)',\n",
       " 'https://io.wikipedia.org/wiki/Pitono',\n",
       " 'https://id.wikipedia.org/wiki/Python',\n",
       " 'https://ia.wikipedia.org/wiki/Python_(disambiguation)',\n",
       " 'https://is.wikipedia.org/wiki/Python_(a%C3%B0greining)',\n",
       " 'https://it.wikipedia.org/wiki/Python_(disambigua)',\n",
       " 'https://he.wikipedia.org/wiki/%D7%A4%D7%99%D7%AA%D7%95%D7%9F',\n",
       " 'https://ka.wikipedia.org/wiki/%E1%83%9E%E1%83%98%E1%83%97%E1%83%9D%E1%83%9C%E1%83%98_(%E1%83%9B%E1%83%A0%E1%83%90%E1%83%95%E1%83%90%E1%83%9A%E1%83%9B%E1%83%9C%E1%83%98%E1%83%A8%E1%83%95%E1%83%9C%E1%83%94%E1%83%9A%E1%83%9D%E1%83%95%E1%83%90%E1%83%9C%E1%83%98)',\n",
       " 'https://kg.wikipedia.org/wiki/Mboma_(nyoka)',\n",
       " 'https://la.wikipedia.org/wiki/Python_(discretiva)',\n",
       " 'https://lb.wikipedia.org/wiki/Python',\n",
       " 'https://hu.wikipedia.org/wiki/Python_(egy%C3%A9rtelm%C5%B1s%C3%ADt%C5%91_lap)',\n",
       " 'https://mr.wikipedia.org/wiki/%E0%A4%AA%E0%A4%BE%E0%A4%AF%E0%A4%A5%E0%A5%89%E0%A4%A8_(%E0%A4%86%E0%A4%9C%E0%A5%8D%E0%A4%9E%E0%A4%BE%E0%A4%B5%E0%A4%B2%E0%A5%80_%E0%A4%AD%E0%A4%BE%E0%A4%B7%E0%A4%BE)',\n",
       " 'https://nl.wikipedia.org/wiki/Python',\n",
       " 'https://ja.wikipedia.org/wiki/%E3%83%91%E3%82%A4%E3%82%BD%E3%83%B3',\n",
       " 'https://no.wikipedia.org/wiki/Pyton',\n",
       " 'https://pl.wikipedia.org/wiki/Pyton',\n",
       " 'https://pt.wikipedia.org/wiki/Python_(desambigua%C3%A7%C3%A3o)',\n",
       " 'https://ru.wikipedia.org/wiki/Python_(%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D1%8F)',\n",
       " 'https://sd.wikipedia.org/wiki/%D8%A7%D8%B1%DA%99',\n",
       " 'https://sk.wikipedia.org/wiki/Python',\n",
       " 'https://sh.wikipedia.org/wiki/Python',\n",
       " 'https://fi.wikipedia.org/wiki/Python',\n",
       " 'https://sv.wikipedia.org/wiki/Pyton',\n",
       " 'https://th.wikipedia.org/wiki/%E0%B9%84%E0%B8%9E%E0%B8%97%E0%B8%AD%E0%B8%99',\n",
       " 'https://tr.wikipedia.org/wiki/Python',\n",
       " 'https://uk.wikipedia.org/wiki/%D0%9F%D1%96%D1%84%D0%BE%D0%BD',\n",
       " 'https://ur.wikipedia.org/wiki/%D9%BE%D8%A7%D8%A6%DB%8C%D8%AA%DA%BE%D9%88%D9%86',\n",
       " 'https://vi.wikipedia.org/wiki/Python',\n",
       " 'https://zh.wikipedia.org/wiki/Python_(%E6%B6%88%E6%AD%A7%E4%B9%89)',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q747452#sitelinks-wikipedia',\n",
       " 'https://foundation.wikimedia.org/wiki/Privacy_policy',\n",
       " 'https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute',\n",
       " 'https://foundation.wikimedia.org/wiki/Cookie_statement',\n",
       " 'https://wikimediafoundation.org/',\n",
       " 'https://www.mediawiki.org/']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_python_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the number of titles that have changed in the United States Code since its last release point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_us = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "html_us = requests.get(url_us).content\n",
    "html_us\n",
    "\n",
    "# Beautiful soup\n",
    "soup_us = BeautifulSoup(html_us, \"lxml\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_us = soup_us.find_all('div',attrs = {'class':\"usctitlechanged\"})\n",
    "#change_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Title 5 - Government Organization and Employees ٭',\n",
       " 'Title 11 - Bankruptcy ٭',\n",
       " 'Title 20 - Education',\n",
       " 'Title 28 - Judiciary and Judicial Procedure ٭',\n",
       " \"Title 38 - Veterans' Benefits ٭\",\n",
       " 'Title 42 - The Public Health and Welfare']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_us_lst = [u.text.replace('\\n', ' ').strip(' ') for u in change_us[0:]]\n",
    "change_us_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find a Python list with the top ten FBI's Most Wanted names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_fbi = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "html_fbi = requests.get(url_fbi).content\n",
    "html_fbi\n",
    "\n",
    "# Beautiful soup\n",
    "soup_fbi = BeautifulSoup(html_fbi, \"lxml\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h3 class=\"title\">\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/jason-derek-brown\">JASON DEREK BROWN</a>\n",
       " </h3>, <h3 class=\"title\">\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/alexis-flores\">ALEXIS FLORES</a>\n",
       " </h3>, <h3 class=\"title\">\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/eugene-palmer\">EUGENE PALMER</a>\n",
       " </h3>, <h3 class=\"title\">\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/santiago-mederos\">SANTIAGO VILLALBA MEDEROS</a>\n",
       " </h3>, <h3 class=\"title\">\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/rafael-caro-quintero\">RAFAEL CARO-QUINTERO</a>\n",
       " </h3>, <h3 class=\"title\">\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/robert-william-fisher\">ROBERT WILLIAM FISHER</a>\n",
       " </h3>, <h3 class=\"title\">\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/bhadreshkumar-chetanbhai-patel\">BHADRESHKUMAR CHETANBHAI PATEL</a>\n",
       " </h3>, <h3 class=\"title\">\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/arnoldo-jimenez\">ARNOLDO JIMENEZ</a>\n",
       " </h3>, <h3 class=\"title\">\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/alejandro-castillo\">ALEJANDRO ROSALES CASTILLO</a>\n",
       " </h3>, <h3 class=\"title\">\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/yaser-abdel-said\">YASER ABDEL SAID</a>\n",
       " </h3>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbi_names = soup_fbi.find_all('h3',attrs = {'class':\"title\"})\n",
    "fbi_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JASON DEREK BROWN',\n",
       " 'ALEXIS FLORES',\n",
       " 'EUGENE PALMER',\n",
       " 'SANTIAGO VILLALBA MEDEROS',\n",
       " 'RAFAEL CARO-QUINTERO',\n",
       " 'ROBERT WILLIAM FISHER',\n",
       " 'BHADRESHKUMAR CHETANBHAI PATEL',\n",
       " 'ARNOLDO JIMENEZ',\n",
       " 'ALEJANDRO ROSALES CASTILLO',\n",
       " 'YASER ABDEL SAID']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbi_names_lst = [f.text.replace('\\n', ' ').strip(' ') for f in fbi_names[0:]]\n",
    "fbi_names_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display the 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_eq = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "html_eq = requests.get(url_eq).content\n",
    "html_eq\n",
    "\n",
    "# Beautiful soup\n",
    "soup_eq = BeautifulSoup(html_eq, \"lxml\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_details = soup_eq.find_all('tbody',attrs = {'id':\"tbody\"})\n",
    "#eq_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[',2019-09-01,,,12:05:32.712min,ago35.60,N,,117.41,W,,9Ml2.5,SOUTHERN,CALIFORNIA2019-09-01,12:09',\n",
       "  ',2019-09-01,,,11:45:47.031min,ago16.14,N,,97.54,W,,8,M4.3,OAXACA,,MEXICO2019-09-01,12:00',\n",
       "  ',2019-09-01,,,11:38:11.039min,ago2.47,N,,126.66,E,,15,M4.2,MOLUCCA,SEA2019-09-01,11:50',\n",
       "  ',2019-09-01,,,11:29:43.747min,ago37.29,N,,104.94,W,,5ML3.7,COLORADO2019-09-01,11:47',\n",
       "  ',2019-09-01,,,10:56:12.21hr,21min,ago35.62,N,,117.44,W,,8Ml2.1,SOUTHERN,CALIFORNIA2019-09-01,10:59',\n",
       "  ',2019-09-01,,,10:34:45.61hr,42min,ago35.67,N,,117.52,W,,10Ml2.0,SOUTHERN,CALIFORNIA2019-09-01,10:38',\n",
       "  '7IV,2019-09-01,,,10:30:43.71hr,46min,ago44.60,N,,18.47,E,,20ML2.6,BOSNIA,AND,HERZEGOVINA2019-09-01,10:47',\n",
       "  '1F,2019-09-01,,,10:16:30.32hr,01min,ago61.45,N,,149.94,W,,30ML3.2,SOUTHERN,ALASKA2019-09-01,11:01',\n",
       "  ',2019-09-01,,,10:11:27.42hr,06min,ago60.55,N,,159.52,W,,9ML2.5,SOUTHERN,ALASKA2019-09-01,11:17',\n",
       "  ',2019-09-01,,,09:50:00.42hr,27min,ago19.35,N,,155.07,W,,1Ml2.0,ISLAND,OF,HAWAII,,HAWAII2019-09-01,09:56',\n",
       "  ',2019-09-01,,,09:25:40.32hr,51min,ago19.40,N,,155.26,W,,0Md2.2,ISLAND,OF,HAWAII,,HAWAII2019-09-01,09:28',\n",
       "  ',2019-09-01,,,09:24:10.62hr,53min,ago37.60,N,,26.86,E,,2ML2.5,DODECANESE,ISLANDS,,GREECE2019-09-01,10:10',\n",
       "  ',2019-09-01,,,08:57:25.83hr,20min,ago37.44,N,,20.41,E,,2ML3.7,IONIAN,SEA2019-09-01,09:52',\n",
       "  ',2019-09-01,,,08:26:48.83hr,50min,ago32.55,N,,115.66,W,,10Ml2.1,BAJA,CALIFORNIA,,MEXICO2019-09-01,08:30',\n",
       "  ',2019-09-01,,,08:19:37.03hr,58min,ago15.62,N,,96.27,W,,3,M4.0,OFFSHORE,OAXACA,,MEXICO2019-09-01,08:43',\n",
       "  ',2019-09-01,,,08:17:29.74hr,00min,ago42.19,N,,71.48,E,,1mb4.6,KYRGYZSTAN2019-09-01,08:31',\n",
       "  ',2019-09-01,,,07:55:33.44hr,22min,ago37.68,N,,21.82,E,,17ML2.6,SOUTHERN,GREECE2019-09-01,08:08',\n",
       "  ',2019-09-01,,,07:38:36.44hr,39min,ago59.05,N,,137.01,W,,3ML2.7,BRITISH,COLUMBIA,,CANADA2019-09-01,08:00',\n",
       "  ',2019-09-01,,,07:25:39.24hr,52min,ago35.90,N,,117.70,W,,7Ml2.1,CENTRAL,CALIFORNIA2019-09-01,07:27',\n",
       "  ',2019-09-01,,,07:16:34.75hr,01min,ago36.38,N,,98.14,W,,2ML2.1,OKLAHOMA2019-09-01,07:23',\n",
       "  ',2019-09-01,,,07:15:44.95hr,01min,ago37.01,N,,15.16,E,,27ML2.7,SICILY,,ITALY2019-09-01,07:27',\n",
       "  'F,2019-09-01,,,07:12:04.75hr,05min,ago37.43,N,,121.77,W,,9Md2.5,SAN,FRANCISCO,BAY,AREA,,CALIF.2019-09-01,07:13',\n",
       "  ',2019-09-01,,,07:02:07.85hr,15min,ago19.16,N,,155.47,W,,33Ml2.1,ISLAND,OF,HAWAII,,HAWAII2019-09-01,07:07',\n",
       "  ',2019-09-01,,,06:34:59.05hr,42min,ago18.11,N,,68.25,W,,133,M3.4,MONA,PASSAGE,,DOMINICAN,REPUBLIC2019-09-01,11:55',\n",
       "  ',2019-09-01,,,06:23:52.15hr,53min,ago5.17,N,,125.24,E,,56mb4.7,MINDANAO,,PHILIPPINES2019-09-01,06:52',\n",
       "  ',2019-09-01,,,06:08:54.26hr,08min,ago59.12,N,,136.80,W,,12ML2.9,SOUTHEASTERN,ALASKA2019-09-01,07:25',\n",
       "  ',2019-09-01,,,06:03:29.06hr,14min,ago36.80,N,,27.71,E,,10ML2.0,DODECANESE,IS.-TURKEY,BORDER,REG2019-09-01,07:03',\n",
       "  ',2019-09-01,,,05:58:03.16hr,19min,ago42.81,N,,13.15,E,,9ML2.8,CENTRAL,ITALY2019-09-01,06:15',\n",
       "  ',2019-09-01,,,05:47:38.06hr,30min,ago24.01,S,,67.43,W,,225ML3.2,ANTOFAGASTA,,CHILE2019-09-01,06:11',\n",
       "  ',2019-09-01,,,05:45:54.56hr,31min,ago36.65,N,,121.25,W,,4Md2.0,CENTRAL,CALIFORNIA2019-09-01,05:47',\n",
       "  ',2019-09-01,,,05:13:30.47hr,04min,ago37.55,N,,26.78,E,,7ML2.1,DODECANESE,ISLANDS,,GREECE2019-09-01,05:24',\n",
       "  ',2019-09-01,,,05:12:05.87hr,05min,ago42.80,N,,13.14,E,,9ML2.7,CENTRAL,ITALY2019-09-01,05:18',\n",
       "  ',2019-09-01,,,05:11:18.57hr,06min,ago59.09,N,,136.91,W,,5ML3.4,SOUTHEASTERN,ALASKA2019-09-01,07:05',\n",
       "  ',2019-09-01,,,05:00:10.07hr,17min,ago30.21,S,,72.36,W,,40ML3.9,OFFSHORE,COQUIMBO,,CHILE2019-09-01,05:31',\n",
       "  ',2019-09-01,,,04:43:35.27hr,34min,ago59.04,N,,136.98,W,,5ML2.3,SOUTHEASTERN,ALASKA2019-09-01,05:04',\n",
       "  '4III,2019-09-01,,,04:32:26.67hr,45min,ago59.13,N,,137.01,W,,10Mw5.0,BRITISH,COLUMBIA,,CANADA2019-09-01,06:51',\n",
       "  ',2019-09-01,,,04:21:25.87hr,56min,ago35.77,N,,117.57,W,,6Ml2.3,SOUTHERN,CALIFORNIA2019-09-01,04:25',\n",
       "  ',2019-09-01,,,04:03:59.48hr,13min,ago39.03,N,,16.49,E,,7ML2.5,SOUTHERN,ITALY2019-09-01,04:12',\n",
       "  ',2019-09-01,,,03:44:15.08hr,33min,ago33.01,S,,70.11,W,,107ML3.1,VALPARAISO,,CHILE2019-09-01,04:07',\n",
       "  ',2019-09-01,,,03:42:33.68hr,35min,ago69.54,N,,144.21,W,,0ML2.8,NORTHERN,ALASKA2019-09-01,03:56',\n",
       "  ',2019-09-01,,,03:37:47.48hr,39min,ago37.51,N,,26.87,E,,7ML2.0,DODECANESE,ISLANDS,,GREECE2019-09-01,05:07',\n",
       "  ',2019-09-01,,,03:36:40.08hr,41min,ago8.18,S,,120.73,E,,10,M4.2,FLORES,REGION,,INDONESIA2019-09-01,03:45',\n",
       "  ',2019-09-01,,,03:29:38.38hr,48min,ago36.07,N,,117.86,W,,3Ml2.1,CENTRAL,CALIFORNIA2019-09-01,03:31',\n",
       "  ',2019-09-01,,,03:18:59.48hr,58min,ago40.44,N,,20.73,E,,15ML2.1,ALBANIA2019-09-01,03:33',\n",
       "  ',2019-09-01,,,03:05:30.09hr,12min,ago10.31,N,,86.29,W,,15,M3.6,OFF,COAST,OF,COSTA,RICA2019-09-01,03:40',\n",
       "  ',2019-09-01,,,02:34:50.49hr,42min,ago49.91,S,,115.13,W,,10Mw5.5,SOUTHERN,EAST,PACIFIC,RISE2019-09-01,06:49',\n",
       "  ',2019-09-01,,,02:31:08.99hr,46min,ago37.32,N,,29.82,E,,7ML2.1,WESTERN,TURKEY2019-09-01,04:55',\n",
       "  ',2019-09-01,,,02:29:20.39hr,48min,ago49.87,N,,156.20,E,,60mb4.0,KURIL,ISLANDS2019-09-01,06:31',\n",
       "  ',2019-09-01,,,02:20:37.39hr,57min,ago66.66,N,,135.78,W,,18ml3.6,NORTHERN,YUKON,TERRITORY,,CANADA2019-09-01,08:30',\n",
       "  ',2019-09-01,,,02:15:40.910hr,01min,ago37.36,N,,29.88,E,,7ML2.0,WESTERN,TURKEY2019-09-01,04:51',\n",
       "  '']]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_details_lst = [q.text.replace('\\xa0',' ').replace('earthquake',' ').replace(' ',',').split(\"\\n\")  for q in eq_details[0:]]\n",
    "#.replace('\\n', ' ').strip('') \n",
    "eq_details_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_list = [item for sublist in eq_details_lst for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,2019-09-01,,,12:05:32.712min,ago35.60,N,,117....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,2019-09-01,,,11:45:47.031min,ago16.14,N,,97.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,2019-09-01,,,11:38:11.039min,ago2.47,N,,126.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,2019-09-01,,,11:29:43.747min,ago37.29,N,,104....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,2019-09-01,,,10:56:12.21hr,21min,ago35.62,N,,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  ,2019-09-01,,,12:05:32.712min,ago35.60,N,,117....\n",
       "1  ,2019-09-01,,,11:45:47.031min,ago16.14,N,,97.5...\n",
       "2  ,2019-09-01,,,11:38:11.039min,ago2.47,N,,126.6...\n",
       "3  ,2019-09-01,,,11:29:43.747min,ago37.29,N,,104....\n",
       "4  ,2019-09-01,,,10:56:12.21hr,21min,ago35.62,N,,..."
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe object from listoftuples\n",
    "df_earthquake = pd.DataFrame(one_list)\n",
    "df_earthquake.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count the number of tweets by a given Twitter account.\n",
    "Ask the user for the handle (@handle) of a twitter account. You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url_twitter = 'https://twitter.com/realDonaldTrump'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> tweets 43942 number of tweets.\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "html_twitter = requests.get(url_twitter)#.content\n",
    "html_twitter\n",
    "\n",
    "# Beautiful soup\n",
    "soup_twitter = BeautifulSoup(html_twitter.text, \"lxml\")  \n",
    "\n",
    "\n",
    "try:\n",
    "    tweet_box = soup_twitter.find('li',{'class':'ProfileNav-item ProfileNav-item--tweets is-active'})\n",
    "    tweets= tweet_box.find('a').find('span',{'class':'ProfileNav-value'})\n",
    "    print(\"{} tweets {} number of tweets.\".format(html_twitter,tweets.get('data-count')))\n",
    "\n",
    "except:\n",
    "    print('Account name not found...')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of followers of a given twitter account\n",
    "Ask the user for the handle (@handle) of a twitter account. You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "#url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of followers: 63796388 \n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "html_twitter = requests.get(url_twitter).content\n",
    "html_twitter\n",
    "\n",
    "# Beautiful soup\n",
    "soup_twitter = BeautifulSoup(html_twitter, \"lxml\")  \n",
    "\n",
    "try:\n",
    "    follow_box = soup_twitter.find('li',{'class':'ProfileNav-item ProfileNav-item--followers'})\n",
    "    followers = follow_box.find('a').find('span',{'class':'ProfileNav-value'})\n",
    "    print(\"Number of followers: {} \".format(followers.get('data-count')))\n",
    "except:\n",
    "    print('Account name not found...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_wiki = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "html_wiki = requests.get(url_wiki).content\n",
    "html_wiki\n",
    "\n",
    "# Beautiful soup\n",
    "soup_wiki = BeautifulSoup(html_wiki, \"lxml\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"central-featured-lang lang1\" dir=\"ltr\" lang=\"en\">\n",
       "<a class=\"link-box\" data-slogan=\"The Free Encyclopedia\" href=\"//en.wikipedia.org/\" id=\"js-link-box-en\" title=\"English — Wikipedia — The Free Encyclopedia\">\n",
       "<strong>English</strong>\n",
       "<small><bdi dir=\"ltr\">5 915 000+</bdi> <span>articles</span></small>\n",
       "</a>\n",
       "</div>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki = soup_wiki.find_all('div',attrs = {'class':\"central-featured-lang\"})\n",
    "wiki[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English: 5 915 000+ articles',\n",
       " '日本語: 1 165 000+ 記事',\n",
       " 'Español: 1 539 000+ artículos',\n",
       " 'Deutsch: 2 336 000+ Artikel',\n",
       " 'Русский: 1 564 000+ статей',\n",
       " 'Français: 2 134 000+ articles',\n",
       " 'Italiano: 1 549 000+ voci',\n",
       " '中文: 1 070 000+ 條目',\n",
       " 'Português: 1 012 000+ artigos',\n",
       " 'Polski: 1 353 000+ haseł']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_lst = [w.text.replace('\\n', ': ').replace(u'\\xa0', u' ').replace(': : ', '') for w in wiki[0:]]\n",
    "wiki_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import re\n",
    "\n",
    "#list_of_list_wiki = [re.findall(r'[a-zA-Z0-9]+',w.text) for w in wiki]\n",
    "\n",
    "#[a-zA-Z0-9]+\n",
    "\n",
    "#[re.findall(r'[a-zA-Zäüö]+', tweet) for tweet in tweets]\n",
    "#list_of_list_wiki\n",
    "#one_list = [item for sublist in list_of_wiki for item in sublist]\n",
    "#one_list \n",
    "                 \n",
    "#list_of_list_word = [re.findall(r'[a-zA-Zäüö]+', tweet) for tweet in tweets]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_uk = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "html_uk = requests.get(url_uk).content\n",
    "html_uk\n",
    "\n",
    "# Beautiful soup\n",
    "soup_uk = BeautifulSoup(html_uk, \"lxml\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk = soup_uk.find_all('div',attrs = {'class':\"grid-row dgu-topics\"})\n",
    "#uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_lst = [u.text.replace('\\n\\n\\n\\n\\n','') for u in uk[0:]]\n",
    "uk_lst = [u.replace('\\n',',') for u in uk_lst[0:]]\n",
    "uk_lst = [u.replace(',,,',',') for u in uk_lst[0:]]\n",
    "uk_lst = [u.replace(',,',',') for u in uk_lst[0:]]\n",
    "uk_lst = [u.strip() for u in uk_lst[0:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy,Small businesses, industry, imports, exports and trade,Crime and justice,Courts, police, prison, offenders, borders and immigration,Defence,Armed forces, health and safety, search and rescue,Education,Students, training, qualifications and the National Curriculum,Environment,Weather, flooding, rivers, air quality, geology and agriculture,Government,Staff numbers and pay, local councillors and department business plans,Government spending,Includes all payments by government departments over £25,000,Health,Includes smoking, drugs, alcohol, medicine performance and hospitals,Mapping,Addresses, boundaries, land ownership, aerial photographs, seabed and land terrain,Society,Employment, benefits, household finances, poverty and population,Towns and cities,Includes housing, urban planning, leisure, waste and energy, consumption,Transport,Airports, roads, freight, electric vehicles, parking, buses and footpaths']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the top 10 languages by number of native speakers stored in a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_nat = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "html_nat = requests.get(url_nat).content\n",
    "\n",
    "soup_nat = BeautifulSoup(html_nat, \"lxml\")\n",
    "#soup_nat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "nat = soup_nat.find_all('table',attrs = {'class':\"wikitable sortable\"})[0]\n",
    "#nat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "nat = nat.find_all('td')\n",
    "#nat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nat_lst = [n.get('title') for n in nat[0:]]\n",
    "nat_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['—',\n",
       " '1',\n",
       " 'Chinese (macrolanguage)',\n",
       " 'China',\n",
       " '39',\n",
       " '1,311',\n",
       " '17.026',\n",
       " '',\n",
       " 'Sino-TibetanSinitic',\n",
       " '1',\n",
       " '—',\n",
       " 'Mandarin',\n",
       " 'China',\n",
       " '13',\n",
       " '918',\n",
       " '11.922',\n",
       " 'Chinese',\n",
       " 'Sino-TibetanSinitic',\n",
       " '2',\n",
       " '2',\n",
       " 'Spanish',\n",
       " 'Spain',\n",
       " '31',\n",
       " '460',\n",
       " '5.974',\n",
       " '',\n",
       " 'Indo-EuropeanRomance',\n",
       " '3',\n",
       " '3',\n",
       " 'English',\n",
       " 'United Kingdom',\n",
       " '137',\n",
       " '379',\n",
       " '4.922',\n",
       " '',\n",
       " 'Indo-EuropeanGermanic',\n",
       " '4',\n",
       " '4',\n",
       " 'Hindi',\n",
       " 'India',\n",
       " '4',\n",
       " '341',\n",
       " '4.429',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '—',\n",
       " '5',\n",
       " 'Arabic (macrolanguage)',\n",
       " 'Saudi Arabia',\n",
       " '59',\n",
       " '319',\n",
       " '4.143',\n",
       " '',\n",
       " 'AfroasiaticSemitic',\n",
       " '5',\n",
       " '6',\n",
       " 'Bengali',\n",
       " 'Bangladesh',\n",
       " '4',\n",
       " '228',\n",
       " '2.961',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '6',\n",
       " '7',\n",
       " 'Portuguese',\n",
       " 'Portugal',\n",
       " '15',\n",
       " '221',\n",
       " '2.870',\n",
       " '',\n",
       " 'Indo-EuropeanRomance',\n",
       " '7',\n",
       " '8',\n",
       " 'Russian',\n",
       " 'Russian Federation',\n",
       " '19',\n",
       " '154',\n",
       " '2.000',\n",
       " '',\n",
       " 'Indo-EuropeanBalto-Slavic',\n",
       " '8',\n",
       " '9',\n",
       " 'Japanese',\n",
       " 'Japan',\n",
       " '2',\n",
       " '128',\n",
       " '1.662',\n",
       " '',\n",
       " 'JaponicJapanese',\n",
       " '—',\n",
       " '10',\n",
       " 'Lahnda (macrolanguage)',\n",
       " 'Pakistan',\n",
       " '6',\n",
       " '119',\n",
       " '1.545',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '9',\n",
       " '—',\n",
       " 'Western Punjabi',\n",
       " 'Pakistan',\n",
       " '2',\n",
       " '92.7',\n",
       " '1.204',\n",
       " 'Lahnda',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '10',\n",
       " '11',\n",
       " 'Marathi',\n",
       " 'India',\n",
       " '1',\n",
       " '83.1',\n",
       " '1.079',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '11',\n",
       " '12',\n",
       " 'Telugu',\n",
       " 'India',\n",
       " '2',\n",
       " '82.0',\n",
       " '1.065',\n",
       " '',\n",
       " 'DravidianSouth-Central',\n",
       " '12',\n",
       " '—',\n",
       " 'Wu',\n",
       " 'China',\n",
       " '1',\n",
       " '81.4',\n",
       " '1.057',\n",
       " 'Chinese',\n",
       " 'Sino-TibetanSinitic',\n",
       " '—',\n",
       " '13',\n",
       " 'Malay (macrolanguage)',\n",
       " 'Malaysia',\n",
       " '20',\n",
       " '80.3',\n",
       " '1.043',\n",
       " '',\n",
       " 'AustronesianMalayo-Polynesian',\n",
       " '13',\n",
       " '14',\n",
       " 'Turkish',\n",
       " 'Turkey',\n",
       " '8',\n",
       " '79.4',\n",
       " '1.031',\n",
       " '',\n",
       " 'TurkicOghuz',\n",
       " '14',\n",
       " '15',\n",
       " 'Korean',\n",
       " 'South Korea',\n",
       " '6',\n",
       " '77.3',\n",
       " '1.004',\n",
       " '',\n",
       " 'Koreaniclanguage isolate',\n",
       " '15',\n",
       " '16',\n",
       " 'French',\n",
       " 'France',\n",
       " '54',\n",
       " '77.2',\n",
       " '1.003',\n",
       " '',\n",
       " 'Indo-EuropeanRomance',\n",
       " '16',\n",
       " '17',\n",
       " 'German',\n",
       " 'Germany',\n",
       " '28',\n",
       " '76.1',\n",
       " '0.988',\n",
       " '',\n",
       " 'Indo-EuropeanGermanic',\n",
       " '17',\n",
       " '18',\n",
       " 'Vietnamese',\n",
       " 'Viet Nam',\n",
       " '4',\n",
       " '76.0',\n",
       " '0.987',\n",
       " '',\n",
       " 'AustroasiaticVietic',\n",
       " '18',\n",
       " '19',\n",
       " 'Tamil',\n",
       " 'India',\n",
       " '7',\n",
       " '75.0',\n",
       " '0.974',\n",
       " '',\n",
       " 'DravidianSouth',\n",
       " '19',\n",
       " '—',\n",
       " 'Yue',\n",
       " 'China',\n",
       " '13',\n",
       " '73.1',\n",
       " '0.949',\n",
       " 'Chinese',\n",
       " 'Sino-TibetanSinitic',\n",
       " '20',\n",
       " '20',\n",
       " 'Urdu',\n",
       " 'Pakistan',\n",
       " '7',\n",
       " '68.6',\n",
       " '0.891',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '21',\n",
       " '21',\n",
       " 'Javanese',\n",
       " 'Indonesia',\n",
       " '3',\n",
       " '68.3',\n",
       " '0.887',\n",
       " '',\n",
       " 'AustronesianMalayo-Polynesian',\n",
       " '22',\n",
       " '22',\n",
       " 'Italian',\n",
       " 'Italy',\n",
       " '14',\n",
       " '64.8',\n",
       " '0.842',\n",
       " '',\n",
       " 'Indo-EuropeanRomance',\n",
       " '23',\n",
       " '—',\n",
       " 'Egyptian Spoken Arabic',\n",
       " 'Egypt',\n",
       " '1',\n",
       " '64.6',\n",
       " '0.839',\n",
       " 'Arabic',\n",
       " 'AfroasiaticSemitic',\n",
       " '—',\n",
       " '23',\n",
       " 'Persian (macrolanguage)',\n",
       " 'Iran',\n",
       " '30',\n",
       " '61.8',\n",
       " '0.803',\n",
       " '',\n",
       " 'Indo-EuropeanIranian',\n",
       " '24',\n",
       " '24',\n",
       " 'Gujarati',\n",
       " 'India',\n",
       " '7',\n",
       " '56.4',\n",
       " '0.732',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '25',\n",
       " '—',\n",
       " 'Iranian Persian',\n",
       " 'Iran',\n",
       " '7',\n",
       " '52.8',\n",
       " '0.686',\n",
       " 'Persian',\n",
       " 'Indo-EuropeanIranian',\n",
       " '26',\n",
       " '25',\n",
       " 'Bhojpuri',\n",
       " 'India',\n",
       " '3',\n",
       " '52.2',\n",
       " '0.678',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '27',\n",
       " '—',\n",
       " 'Min Nan',\n",
       " 'China',\n",
       " '10',\n",
       " '50.1',\n",
       " '0.651',\n",
       " 'Chinese',\n",
       " 'Sino-TibetanSinitic',\n",
       " '28',\n",
       " '—',\n",
       " 'Hakka',\n",
       " 'China',\n",
       " '13',\n",
       " '48.2',\n",
       " '0.626',\n",
       " 'Chinese',\n",
       " 'Sino-TibetanSinitic',\n",
       " '29',\n",
       " '—',\n",
       " 'Jinyu',\n",
       " 'China',\n",
       " '1',\n",
       " '46.9',\n",
       " '0.609',\n",
       " 'Chinese',\n",
       " 'Sino-TibetanSinitic',\n",
       " '30',\n",
       " '26',\n",
       " 'Hausa',\n",
       " 'Nigeria',\n",
       " '9',\n",
       " '43.9',\n",
       " '0.570',\n",
       " '',\n",
       " 'AfroasiaticChadic',\n",
       " '31',\n",
       " '27',\n",
       " 'Kannada',\n",
       " 'India',\n",
       " '1',\n",
       " '43.6',\n",
       " '0.566',\n",
       " '',\n",
       " 'DravidianSouth',\n",
       " '32',\n",
       " '—',\n",
       " 'Indonesian',\n",
       " 'Indonesia',\n",
       " '1',\n",
       " '43.4',\n",
       " '0.564',\n",
       " 'Malay',\n",
       " 'AustronesianMalayo-Polynesian',\n",
       " '33',\n",
       " '28',\n",
       " 'Polish',\n",
       " 'Poland',\n",
       " '10',\n",
       " '39.7',\n",
       " '0.516',\n",
       " '',\n",
       " 'Indo-EuropeanBalto-Slavic',\n",
       " '—',\n",
       " '29',\n",
       " 'Pushto (macrolanguage)',\n",
       " 'Pakistan',\n",
       " '5',\n",
       " '38.2',\n",
       " '0.496',\n",
       " '',\n",
       " 'Indo-EuropeanIranian',\n",
       " '34',\n",
       " '30',\n",
       " 'Yoruba',\n",
       " 'Nigeria',\n",
       " '3',\n",
       " '37.8',\n",
       " '0.491',\n",
       " '',\n",
       " 'Niger–CongoVolta–Niger',\n",
       " '35',\n",
       " '—',\n",
       " 'Xiang Chinese',\n",
       " 'China',\n",
       " '1',\n",
       " '37.3',\n",
       " '0.484',\n",
       " 'Chinese',\n",
       " 'Sino-TibetanSinitic',\n",
       " '36',\n",
       " '31',\n",
       " 'Malayalam',\n",
       " 'India',\n",
       " '2',\n",
       " '37.1',\n",
       " '0.482',\n",
       " '',\n",
       " 'DravidianSouth',\n",
       " '—',\n",
       " '32',\n",
       " 'Oriya (macrolanguage)',\n",
       " 'India',\n",
       " '1',\n",
       " '37.1',\n",
       " '0.482',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '37',\n",
       " '—',\n",
       " 'Odia',\n",
       " 'India',\n",
       " '1',\n",
       " '34.5',\n",
       " '0.448',\n",
       " 'Oriya',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '38',\n",
       " '33',\n",
       " 'Maithili',\n",
       " 'India',\n",
       " '2',\n",
       " '33.9',\n",
       " '0.440',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '39',\n",
       " '34',\n",
       " 'Burmese',\n",
       " 'Myanmar',\n",
       " '1',\n",
       " '32.9',\n",
       " '0.427',\n",
       " '',\n",
       " 'Sino-TibetanLolo-Burmese',\n",
       " '40',\n",
       " '35',\n",
       " 'Eastern Punjabi',\n",
       " 'India',\n",
       " '3',\n",
       " '32.6',\n",
       " '0.423',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '41',\n",
       " '36',\n",
       " 'Sunda',\n",
       " 'Indonesia',\n",
       " '1',\n",
       " '32.4',\n",
       " '0.421',\n",
       " '',\n",
       " 'AustronesianMalayo-Polynesian',\n",
       " '42',\n",
       " '—',\n",
       " 'Sudanese Spoken Arabic',\n",
       " 'Sudan',\n",
       " '4',\n",
       " '31.9',\n",
       " '0.414',\n",
       " 'Arabic',\n",
       " 'AfroasiaticSemitic',\n",
       " '—',\n",
       " '37',\n",
       " 'Fulah (macrolanguage)',\n",
       " 'Senegal',\n",
       " '19',\n",
       " '29.8',\n",
       " '0.387',\n",
       " '',\n",
       " 'Niger–CongoSenegambian',\n",
       " '—',\n",
       " '38',\n",
       " 'Uzbek (macrolanguage)',\n",
       " 'Uzbekistan',\n",
       " '8',\n",
       " '29.5',\n",
       " '0.383',\n",
       " '',\n",
       " 'TurkicKarluk',\n",
       " '43',\n",
       " '—',\n",
       " 'Algerian Spoken Arabic',\n",
       " 'Algeria',\n",
       " '2',\n",
       " '29.4',\n",
       " '0.382',\n",
       " 'Arabic',\n",
       " 'AfroasiaticSemitic',\n",
       " '44',\n",
       " '—',\n",
       " 'Moroccan Spoken Arabic',\n",
       " 'Morocco',\n",
       " '3',\n",
       " '27.5',\n",
       " '0.357',\n",
       " 'Arabic',\n",
       " 'AfroasiaticSemitic',\n",
       " '45',\n",
       " '39',\n",
       " 'Ukrainian',\n",
       " 'Ukraine',\n",
       " '9',\n",
       " '27.3',\n",
       " '0.355',\n",
       " '',\n",
       " 'Indo-EuropeanBalto-Slavic',\n",
       " '46',\n",
       " '40',\n",
       " 'Igbo',\n",
       " 'Nigeria',\n",
       " '1',\n",
       " '27.0',\n",
       " '0.351',\n",
       " '',\n",
       " 'Niger–CongoVolta–Niger',\n",
       " '47',\n",
       " '—',\n",
       " 'Northern Uzbek',\n",
       " 'Uzbekistan',\n",
       " '6',\n",
       " '25.1',\n",
       " '0.326',\n",
       " 'Uzbek',\n",
       " 'TurkicKarluk',\n",
       " '48',\n",
       " '41',\n",
       " 'Sindhi',\n",
       " 'Pakistan',\n",
       " '3',\n",
       " '24.6',\n",
       " '0.319',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '49',\n",
       " '—',\n",
       " 'North Levantine Spoken Arabic',\n",
       " 'Syria',\n",
       " '5',\n",
       " '24.6',\n",
       " '0.319',\n",
       " 'Arabic',\n",
       " 'AfroasiaticSemitic',\n",
       " '50',\n",
       " '42',\n",
       " 'Romanian',\n",
       " 'Romania',\n",
       " '6',\n",
       " '24.3',\n",
       " '0.316',\n",
       " '',\n",
       " 'Indo-EuropeanRomance',\n",
       " '51',\n",
       " '43',\n",
       " 'Tagalog',\n",
       " 'Philippines',\n",
       " '3',\n",
       " '23.6',\n",
       " '0.306',\n",
       " '',\n",
       " 'AustronesianMalayo-Polynesian',\n",
       " '52',\n",
       " '44',\n",
       " 'Dutch',\n",
       " 'Netherlands',\n",
       " '7',\n",
       " '23.1',\n",
       " '0.300',\n",
       " '',\n",
       " 'Indo-EuropeanGermanic',\n",
       " '—',\n",
       " '45',\n",
       " 'Azerbaijani (macrolanguage)',\n",
       " 'Iran',\n",
       " '8',\n",
       " '23.0',\n",
       " '0.299',\n",
       " '',\n",
       " 'TurkicOghuz',\n",
       " '53',\n",
       " '—',\n",
       " 'Saʽidi Spoken Arabic',\n",
       " 'Egypt',\n",
       " '1',\n",
       " '22.4',\n",
       " '0.291',\n",
       " 'Arabic',\n",
       " 'AfroasiaticSemitic',\n",
       " '—',\n",
       " '46',\n",
       " 'Kurdish (macrolanguage)',\n",
       " 'Iraq',\n",
       " '9',\n",
       " '22.1',\n",
       " '0.287',\n",
       " '',\n",
       " 'Indo-EuropeanIranian',\n",
       " '54',\n",
       " '—',\n",
       " 'Gan',\n",
       " 'China',\n",
       " '1',\n",
       " '22.1',\n",
       " '0.287',\n",
       " 'Chinese',\n",
       " 'Sino-TibetanSinitic',\n",
       " '55',\n",
       " '47',\n",
       " 'Amharic',\n",
       " 'Ethiopia',\n",
       " '2',\n",
       " '21.9',\n",
       " '0.284',\n",
       " '',\n",
       " 'AfroasiaticSemitic',\n",
       " '56',\n",
       " '—',\n",
       " 'Northern Pashto',\n",
       " 'Pakistan',\n",
       " '4',\n",
       " '20.9',\n",
       " '0.271',\n",
       " 'Pushto',\n",
       " 'Indo-EuropeanIranian',\n",
       " '57',\n",
       " '48',\n",
       " 'Magahi',\n",
       " 'India',\n",
       " '2',\n",
       " '20.7',\n",
       " '0.269',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '58',\n",
       " '49',\n",
       " 'Thai',\n",
       " 'Thailand',\n",
       " '2',\n",
       " '20.7',\n",
       " '0.269',\n",
       " '',\n",
       " 'Kra–DaiTai',\n",
       " '—',\n",
       " '50',\n",
       " 'Marwari (macrolanguage)',\n",
       " 'India',\n",
       " '3',\n",
       " '20.6',\n",
       " '0.268',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '59',\n",
       " '—',\n",
       " 'Saraiki',\n",
       " 'Pakistan',\n",
       " '2',\n",
       " '20.0',\n",
       " '0.260',\n",
       " 'Lahnda',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '—',\n",
       " '51',\n",
       " 'Malagasy (macrolanguage)',\n",
       " 'Madagascar',\n",
       " '2',\n",
       " '18.1',\n",
       " '0.235',\n",
       " '',\n",
       " 'AustronesianMalayo-Polynesian',\n",
       " '—',\n",
       " '52',\n",
       " 'Oromo (macrolanguage)',\n",
       " 'Ethiopia',\n",
       " '3',\n",
       " '17.5',\n",
       " '0.227',\n",
       " '',\n",
       " 'AfroasiaticCushitic',\n",
       " '—',\n",
       " '53',\n",
       " 'Serbo-Croatian (macrolanguage)',\n",
       " 'Serbia',\n",
       " '13',\n",
       " '17.1',\n",
       " '0.222',\n",
       " '',\n",
       " 'Indo-EuropeanBalto-Slavic',\n",
       " '—',\n",
       " '54',\n",
       " 'Nepali (macrolanguage)',\n",
       " 'Nepal',\n",
       " '3',\n",
       " '16.6',\n",
       " '0.216',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '60',\n",
       " '55',\n",
       " 'Khmer',\n",
       " 'Cambodia',\n",
       " '2',\n",
       " '16.6',\n",
       " '0.216',\n",
       " '',\n",
       " 'AustroasiaticKhmer',\n",
       " '61',\n",
       " '56',\n",
       " 'Chhattisgarhi',\n",
       " 'India',\n",
       " '1',\n",
       " '16.3',\n",
       " '0.212',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '62',\n",
       " '57',\n",
       " 'Somali',\n",
       " 'Somalia',\n",
       " '4',\n",
       " '16.2',\n",
       " '0.210',\n",
       " '',\n",
       " 'AfroasiaticCushitic',\n",
       " '63',\n",
       " '—',\n",
       " 'Malay',\n",
       " 'Malaysia',\n",
       " '3',\n",
       " '16.1',\n",
       " '0.209',\n",
       " 'Malay',\n",
       " 'AustronesianMalayo-Polynesian',\n",
       " '64',\n",
       " '58',\n",
       " 'Cebuano',\n",
       " 'Philippines',\n",
       " '1',\n",
       " '15.9',\n",
       " '0.206',\n",
       " '',\n",
       " 'AustronesianMalayo-Polynesian',\n",
       " '65',\n",
       " '—',\n",
       " 'Nepali',\n",
       " 'Nepal',\n",
       " '3',\n",
       " '15.8',\n",
       " '0.205',\n",
       " 'Nepali',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '66',\n",
       " '—',\n",
       " 'Mesopotamian Spoken Arabic',\n",
       " 'Iraq',\n",
       " '4',\n",
       " '15.7',\n",
       " '0.204',\n",
       " 'Arabic',\n",
       " 'AfroasiaticSemitic',\n",
       " '67',\n",
       " '59',\n",
       " 'Assamese',\n",
       " 'India',\n",
       " '1',\n",
       " '15.3',\n",
       " '0.199',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '68',\n",
       " '60',\n",
       " 'Sinhala',\n",
       " 'Sri Lanka',\n",
       " '2',\n",
       " '15.3',\n",
       " '0.199',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '—',\n",
       " '61',\n",
       " 'Zhuang (macrolanguage)',\n",
       " 'China',\n",
       " '2',\n",
       " '14.9',\n",
       " '0.194',\n",
       " '',\n",
       " 'Kra–DaiTai',\n",
       " '69',\n",
       " '—',\n",
       " 'Northern Kurdish',\n",
       " 'Turkey',\n",
       " '9',\n",
       " '14.6',\n",
       " '0.190',\n",
       " 'Kurdish',\n",
       " 'Indo-EuropeanIranian',\n",
       " '70',\n",
       " '—',\n",
       " 'Hijazi Spoken Arabic',\n",
       " 'Saudi Arabia',\n",
       " '3',\n",
       " '14.5',\n",
       " '0.188',\n",
       " 'Arabic',\n",
       " 'AfroasiaticSemitic',\n",
       " '71',\n",
       " '—',\n",
       " 'Nigerian Fulfulde',\n",
       " 'Nigeria',\n",
       " '3',\n",
       " '14.5',\n",
       " '0.188',\n",
       " 'Fulah',\n",
       " 'Niger–CongoSenegambian',\n",
       " '72',\n",
       " '—',\n",
       " 'South Azerbaijani',\n",
       " 'Iran',\n",
       " '5',\n",
       " '13.8',\n",
       " '0.179',\n",
       " 'Azerbaijani',\n",
       " 'TurkicOghuz',\n",
       " '73',\n",
       " '62',\n",
       " 'Greek',\n",
       " 'Greece',\n",
       " '9',\n",
       " '13.1',\n",
       " '0.170',\n",
       " '',\n",
       " 'Indo-EuropeanHellenic',\n",
       " '74',\n",
       " '63',\n",
       " 'Chittagonian',\n",
       " 'Bangladesh',\n",
       " '1',\n",
       " '13.0',\n",
       " '0.169',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '75',\n",
       " '64',\n",
       " 'Kazakh',\n",
       " 'Kazakhstan',\n",
       " '6',\n",
       " '12.9',\n",
       " '0.168',\n",
       " '',\n",
       " 'TurkicKipchak',\n",
       " '76',\n",
       " '65',\n",
       " 'Deccan',\n",
       " 'India',\n",
       " '1',\n",
       " '12.8',\n",
       " '0.166',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '77',\n",
       " '66',\n",
       " 'Hungarian',\n",
       " 'Hungary',\n",
       " '9',\n",
       " '12.6',\n",
       " '0.164',\n",
       " '',\n",
       " 'UralicUgric',\n",
       " '78',\n",
       " '67',\n",
       " 'Kinyarwanda',\n",
       " 'Rwanda',\n",
       " '3',\n",
       " '12.1',\n",
       " '0.157',\n",
       " '',\n",
       " 'Niger–CongoBantu',\n",
       " '79',\n",
       " '68',\n",
       " 'Zulu',\n",
       " 'South Africa',\n",
       " '5',\n",
       " '12.1',\n",
       " '0.157',\n",
       " '',\n",
       " 'Niger–CongoBantu',\n",
       " '80',\n",
       " '—',\n",
       " 'South Levantine Spoken Arabic',\n",
       " 'Jordan',\n",
       " '4',\n",
       " '11.6',\n",
       " '0.151',\n",
       " 'Arabic',\n",
       " 'AfroasiaticSemitic',\n",
       " '81',\n",
       " '—',\n",
       " 'Tunisian Spoken Arabic',\n",
       " 'Tunisia',\n",
       " '1',\n",
       " '11.6',\n",
       " '0.151',\n",
       " 'Arabic',\n",
       " 'AfroasiaticSemitic',\n",
       " '82',\n",
       " '—',\n",
       " 'Sanaani Spoken Arabic',\n",
       " 'Yemen',\n",
       " '1',\n",
       " '11.4',\n",
       " '0.148',\n",
       " 'Arabic',\n",
       " 'AfroasiaticSemitic',\n",
       " '83',\n",
       " '—',\n",
       " 'Min Bei Chinese',\n",
       " 'China',\n",
       " '2',\n",
       " '11.0',\n",
       " '0.143',\n",
       " 'Chinese',\n",
       " 'Sino-TibetanSinitic',\n",
       " '84',\n",
       " '—',\n",
       " 'Southern Pashto',\n",
       " 'Afghanistan',\n",
       " '4',\n",
       " '10.9',\n",
       " '0.142',\n",
       " 'Pushto',\n",
       " 'Indo-EuropeanIranian',\n",
       " '85',\n",
       " '69',\n",
       " 'Rundi',\n",
       " 'Burundi',\n",
       " '2',\n",
       " '10.8',\n",
       " '0.140',\n",
       " '',\n",
       " 'Niger–CongoBantu',\n",
       " '86',\n",
       " '70',\n",
       " 'Czech',\n",
       " 'Czech Republic',\n",
       " '8',\n",
       " '10.7',\n",
       " '0.139',\n",
       " '',\n",
       " 'Indo-EuropeanBalto-Slavic',\n",
       " '87',\n",
       " '—',\n",
       " 'Taʽizzi-Adeni Spoken Arabic',\n",
       " 'Yemen',\n",
       " '2',\n",
       " '10.5',\n",
       " '0.136',\n",
       " 'Arabic',\n",
       " 'AfroasiaticSemitic',\n",
       " '88',\n",
       " '71',\n",
       " 'Uyghur',\n",
       " 'China',\n",
       " '4',\n",
       " '10.4',\n",
       " '0.135',\n",
       " '',\n",
       " 'TurkicKarluk',\n",
       " '89',\n",
       " '—',\n",
       " 'Min Dong Chinese',\n",
       " 'China',\n",
       " '6',\n",
       " '10.3',\n",
       " '0.134',\n",
       " 'Chinese',\n",
       " 'Sino-TibetanSinitic',\n",
       " '90',\n",
       " '72',\n",
       " 'Sylheti',\n",
       " 'Bangladesh',\n",
       " '2',\n",
       " '10.3',\n",
       " '0.134',\n",
       " '',\n",
       " 'Indo-EuropeanIndo-Aryan',\n",
       " '—',\n",
       " '73',\n",
       " 'Baluchi (macrolanguage)',\n",
       " 'Pakistan',\n",
       " '7',\n",
       " '10.0',\n",
       " '0.130',\n",
       " '',\n",
       " 'Indo-EuropeanIranian']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nat_lst = [n.text.replace('\\n','') for n in nat_rows[0:]]\n",
    "#('\\n','')\n",
    "nat_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " ['Chinese', 'macrolanguage'],\n",
       " ['China'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Sino', 'TibetanSinitic'],\n",
       " [],\n",
       " [],\n",
       " ['Mandarin'],\n",
       " ['China'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Chinese'],\n",
       " ['Sino', 'TibetanSinitic'],\n",
       " [],\n",
       " [],\n",
       " ['Spanish'],\n",
       " ['Spain'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanRomance'],\n",
       " [],\n",
       " [],\n",
       " ['English'],\n",
       " ['United', 'Kingdom'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanGermanic'],\n",
       " [],\n",
       " [],\n",
       " ['Hindi'],\n",
       " ['India'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Arabic', 'macrolanguage'],\n",
       " ['Saudi', 'Arabia'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['AfroasiaticSemitic'],\n",
       " [],\n",
       " [],\n",
       " ['Bengali'],\n",
       " ['Bangladesh'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Portuguese'],\n",
       " ['Portugal'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanRomance'],\n",
       " [],\n",
       " [],\n",
       " ['Russian'],\n",
       " ['Russian', 'Federation'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanBalto', 'Slavic'],\n",
       " [],\n",
       " [],\n",
       " ['Japanese'],\n",
       " ['Japan'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['JaponicJapanese'],\n",
       " [],\n",
       " [],\n",
       " ['Lahnda', 'macrolanguage'],\n",
       " ['Pakistan'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Western', 'Punjabi'],\n",
       " ['Pakistan'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Lahnda'],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Marathi'],\n",
       " ['India'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Telugu'],\n",
       " ['India'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['DravidianSouth', 'Central'],\n",
       " [],\n",
       " [],\n",
       " ['Wu'],\n",
       " ['China'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Chinese'],\n",
       " ['Sino', 'TibetanSinitic'],\n",
       " [],\n",
       " [],\n",
       " ['Malay', 'macrolanguage'],\n",
       " ['Malaysia'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['AustronesianMalayo', 'Polynesian'],\n",
       " [],\n",
       " [],\n",
       " ['Turkish'],\n",
       " ['Turkey'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['TurkicOghuz'],\n",
       " [],\n",
       " [],\n",
       " ['Korean'],\n",
       " ['South', 'Korea'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Koreaniclanguage', 'isolate'],\n",
       " [],\n",
       " [],\n",
       " ['French'],\n",
       " ['France'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanRomance'],\n",
       " [],\n",
       " [],\n",
       " ['German'],\n",
       " ['Germany'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanGermanic'],\n",
       " [],\n",
       " [],\n",
       " ['Vietnamese'],\n",
       " ['Viet', 'Nam'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['AustroasiaticVietic'],\n",
       " [],\n",
       " [],\n",
       " ['Tamil'],\n",
       " ['India'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['DravidianSouth'],\n",
       " [],\n",
       " [],\n",
       " ['Yue'],\n",
       " ['China'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Chinese'],\n",
       " ['Sino', 'TibetanSinitic'],\n",
       " [],\n",
       " [],\n",
       " ['Urdu'],\n",
       " ['Pakistan'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Javanese'],\n",
       " ['Indonesia'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['AustronesianMalayo', 'Polynesian'],\n",
       " [],\n",
       " [],\n",
       " ['Italian'],\n",
       " ['Italy'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanRomance'],\n",
       " [],\n",
       " [],\n",
       " ['Egyptian', 'Spoken', 'Arabic'],\n",
       " ['Egypt'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Arabic'],\n",
       " ['AfroasiaticSemitic'],\n",
       " [],\n",
       " [],\n",
       " ['Persian', 'macrolanguage'],\n",
       " ['Iran'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIranian'],\n",
       " [],\n",
       " [],\n",
       " ['Gujarati'],\n",
       " ['India'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Iranian', 'Persian'],\n",
       " ['Iran'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Persian'],\n",
       " ['Indo', 'EuropeanIranian'],\n",
       " [],\n",
       " [],\n",
       " ['Bhojpuri'],\n",
       " ['India'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Min', 'Nan'],\n",
       " ['China'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Chinese'],\n",
       " ['Sino', 'TibetanSinitic'],\n",
       " [],\n",
       " [],\n",
       " ['Hakka'],\n",
       " ['China'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Chinese'],\n",
       " ['Sino', 'TibetanSinitic'],\n",
       " [],\n",
       " [],\n",
       " ['Jinyu'],\n",
       " ['China'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Chinese'],\n",
       " ['Sino', 'TibetanSinitic'],\n",
       " [],\n",
       " [],\n",
       " ['Hausa'],\n",
       " ['Nigeria'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['AfroasiaticChadic'],\n",
       " [],\n",
       " [],\n",
       " ['Kannada'],\n",
       " ['India'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['DravidianSouth'],\n",
       " [],\n",
       " [],\n",
       " ['Indonesian'],\n",
       " ['Indonesia'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Malay'],\n",
       " ['AustronesianMalayo', 'Polynesian'],\n",
       " [],\n",
       " [],\n",
       " ['Polish'],\n",
       " ['Poland'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanBalto', 'Slavic'],\n",
       " [],\n",
       " [],\n",
       " ['Pushto', 'macrolanguage'],\n",
       " ['Pakistan'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIranian'],\n",
       " [],\n",
       " [],\n",
       " ['Yoruba'],\n",
       " ['Nigeria'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Niger', 'CongoVolta', 'Niger'],\n",
       " [],\n",
       " [],\n",
       " ['Xiang', 'Chinese'],\n",
       " ['China'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Chinese'],\n",
       " ['Sino', 'TibetanSinitic'],\n",
       " [],\n",
       " [],\n",
       " ['Malayalam'],\n",
       " ['India'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['DravidianSouth'],\n",
       " [],\n",
       " [],\n",
       " ['Oriya', 'macrolanguage'],\n",
       " ['India'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Odia'],\n",
       " ['India'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Oriya'],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Maithili'],\n",
       " ['India'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Burmese'],\n",
       " ['Myanmar'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Sino', 'TibetanLolo', 'Burmese'],\n",
       " [],\n",
       " [],\n",
       " ['Eastern', 'Punjabi'],\n",
       " ['India'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Sunda'],\n",
       " ['Indonesia'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['AustronesianMalayo', 'Polynesian'],\n",
       " [],\n",
       " [],\n",
       " ['Sudanese', 'Spoken', 'Arabic'],\n",
       " ['Sudan'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Arabic'],\n",
       " ['AfroasiaticSemitic'],\n",
       " [],\n",
       " [],\n",
       " ['Fulah', 'macrolanguage'],\n",
       " ['Senegal'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Niger', 'CongoSenegambian'],\n",
       " [],\n",
       " [],\n",
       " ['Uzbek', 'macrolanguage'],\n",
       " ['Uzbekistan'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['TurkicKarluk'],\n",
       " [],\n",
       " [],\n",
       " ['Algerian', 'Spoken', 'Arabic'],\n",
       " ['Algeria'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Arabic'],\n",
       " ['AfroasiaticSemitic'],\n",
       " [],\n",
       " [],\n",
       " ['Moroccan', 'Spoken', 'Arabic'],\n",
       " ['Morocco'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Arabic'],\n",
       " ['AfroasiaticSemitic'],\n",
       " [],\n",
       " [],\n",
       " ['Ukrainian'],\n",
       " ['Ukraine'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanBalto', 'Slavic'],\n",
       " [],\n",
       " [],\n",
       " ['Igbo'],\n",
       " ['Nigeria'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Niger', 'CongoVolta', 'Niger'],\n",
       " [],\n",
       " [],\n",
       " ['Northern', 'Uzbek'],\n",
       " ['Uzbekistan'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Uzbek'],\n",
       " ['TurkicKarluk'],\n",
       " [],\n",
       " [],\n",
       " ['Sindhi'],\n",
       " ['Pakistan'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['North', 'Levantine', 'Spoken', 'Arabic'],\n",
       " ['Syria'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Arabic'],\n",
       " ['AfroasiaticSemitic'],\n",
       " [],\n",
       " [],\n",
       " ['Romanian'],\n",
       " ['Romania'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanRomance'],\n",
       " [],\n",
       " [],\n",
       " ['Tagalog'],\n",
       " ['Philippines'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['AustronesianMalayo', 'Polynesian'],\n",
       " [],\n",
       " [],\n",
       " ['Dutch'],\n",
       " ['Netherlands'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanGermanic'],\n",
       " [],\n",
       " [],\n",
       " ['Azerbaijani', 'macrolanguage'],\n",
       " ['Iran'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['TurkicOghuz'],\n",
       " [],\n",
       " [],\n",
       " ['Sa', 'idi', 'Spoken', 'Arabic'],\n",
       " ['Egypt'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Arabic'],\n",
       " ['AfroasiaticSemitic'],\n",
       " [],\n",
       " [],\n",
       " ['Kurdish', 'macrolanguage'],\n",
       " ['Iraq'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIranian'],\n",
       " [],\n",
       " [],\n",
       " ['Gan'],\n",
       " ['China'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Chinese'],\n",
       " ['Sino', 'TibetanSinitic'],\n",
       " [],\n",
       " [],\n",
       " ['Amharic'],\n",
       " ['Ethiopia'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['AfroasiaticSemitic'],\n",
       " [],\n",
       " [],\n",
       " ['Northern', 'Pashto'],\n",
       " ['Pakistan'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Pushto'],\n",
       " ['Indo', 'EuropeanIranian'],\n",
       " [],\n",
       " [],\n",
       " ['Magahi'],\n",
       " ['India'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Thai'],\n",
       " ['Thailand'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Kra', 'DaiTai'],\n",
       " [],\n",
       " [],\n",
       " ['Marwari', 'macrolanguage'],\n",
       " ['India'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Saraiki'],\n",
       " ['Pakistan'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Lahnda'],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Malagasy', 'macrolanguage'],\n",
       " ['Madagascar'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['AustronesianMalayo', 'Polynesian'],\n",
       " [],\n",
       " [],\n",
       " ['Oromo', 'macrolanguage'],\n",
       " ['Ethiopia'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['AfroasiaticCushitic'],\n",
       " [],\n",
       " [],\n",
       " ['Serbo', 'Croatian', 'macrolanguage'],\n",
       " ['Serbia'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanBalto', 'Slavic'],\n",
       " [],\n",
       " [],\n",
       " ['Nepali', 'macrolanguage'],\n",
       " ['Nepal'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Khmer'],\n",
       " ['Cambodia'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['AustroasiaticKhmer'],\n",
       " [],\n",
       " [],\n",
       " ['Chhattisgarhi'],\n",
       " ['India'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Somali'],\n",
       " ['Somalia'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['AfroasiaticCushitic'],\n",
       " [],\n",
       " [],\n",
       " ['Malay'],\n",
       " ['Malaysia'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Malay'],\n",
       " ['AustronesianMalayo', 'Polynesian'],\n",
       " [],\n",
       " [],\n",
       " ['Cebuano'],\n",
       " ['Philippines'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['AustronesianMalayo', 'Polynesian'],\n",
       " [],\n",
       " [],\n",
       " ['Nepali'],\n",
       " ['Nepal'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Nepali'],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Mesopotamian', 'Spoken', 'Arabic'],\n",
       " ['Iraq'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Arabic'],\n",
       " ['AfroasiaticSemitic'],\n",
       " [],\n",
       " [],\n",
       " ['Assamese'],\n",
       " ['India'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Sinhala'],\n",
       " ['Sri', 'Lanka'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Zhuang', 'macrolanguage'],\n",
       " ['China'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Kra', 'DaiTai'],\n",
       " [],\n",
       " [],\n",
       " ['Northern', 'Kurdish'],\n",
       " ['Turkey'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Kurdish'],\n",
       " ['Indo', 'EuropeanIranian'],\n",
       " [],\n",
       " [],\n",
       " ['Hijazi', 'Spoken', 'Arabic'],\n",
       " ['Saudi', 'Arabia'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Arabic'],\n",
       " ['AfroasiaticSemitic'],\n",
       " [],\n",
       " [],\n",
       " ['Nigerian', 'Fulfulde'],\n",
       " ['Nigeria'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Fulah'],\n",
       " ['Niger', 'CongoSenegambian'],\n",
       " [],\n",
       " [],\n",
       " ['South', 'Azerbaijani'],\n",
       " ['Iran'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Azerbaijani'],\n",
       " ['TurkicOghuz'],\n",
       " [],\n",
       " [],\n",
       " ['Greek'],\n",
       " ['Greece'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanHellenic'],\n",
       " [],\n",
       " [],\n",
       " ['Chittagonian'],\n",
       " ['Bangladesh'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Kazakh'],\n",
       " ['Kazakhstan'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['TurkicKipchak'],\n",
       " [],\n",
       " [],\n",
       " ['Deccan'],\n",
       " ['India'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Hungarian'],\n",
       " ['Hungary'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['UralicUgric'],\n",
       " [],\n",
       " [],\n",
       " ['Kinyarwanda'],\n",
       " ['Rwanda'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Niger', 'CongoBantu'],\n",
       " [],\n",
       " [],\n",
       " ['Zulu'],\n",
       " ['South', 'Africa'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Niger', 'CongoBantu'],\n",
       " [],\n",
       " [],\n",
       " ['South', 'Levantine', 'Spoken', 'Arabic'],\n",
       " ['Jordan'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Arabic'],\n",
       " ['AfroasiaticSemitic'],\n",
       " [],\n",
       " [],\n",
       " ['Tunisian', 'Spoken', 'Arabic'],\n",
       " ['Tunisia'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Arabic'],\n",
       " ['AfroasiaticSemitic'],\n",
       " [],\n",
       " [],\n",
       " ['Sanaani', 'Spoken', 'Arabic'],\n",
       " ['Yemen'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Arabic'],\n",
       " ['AfroasiaticSemitic'],\n",
       " [],\n",
       " [],\n",
       " ['Min', 'Bei', 'Chinese'],\n",
       " ['China'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Chinese'],\n",
       " ['Sino', 'TibetanSinitic'],\n",
       " [],\n",
       " [],\n",
       " ['Southern', 'Pashto'],\n",
       " ['Afghanistan'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Pushto'],\n",
       " ['Indo', 'EuropeanIranian'],\n",
       " [],\n",
       " [],\n",
       " ['Rundi'],\n",
       " ['Burundi'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Niger', 'CongoBantu'],\n",
       " [],\n",
       " [],\n",
       " ['Czech'],\n",
       " ['Czech', 'Republic'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanBalto', 'Slavic'],\n",
       " [],\n",
       " [],\n",
       " ['Ta', 'izzi', 'Adeni', 'Spoken', 'Arabic'],\n",
       " ['Yemen'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Arabic'],\n",
       " ['AfroasiaticSemitic'],\n",
       " [],\n",
       " [],\n",
       " ['Uyghur'],\n",
       " ['China'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['TurkicKarluk'],\n",
       " [],\n",
       " [],\n",
       " ['Min', 'Dong', 'Chinese'],\n",
       " ['China'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Chinese'],\n",
       " ['Sino', 'TibetanSinitic'],\n",
       " [],\n",
       " [],\n",
       " ['Sylheti'],\n",
       " ['Bangladesh'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIndo', 'Aryan'],\n",
       " [],\n",
       " [],\n",
       " ['Baluchi', 'macrolanguage'],\n",
       " ['Pakistan'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Indo', 'EuropeanIranian']]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "list_of_nat = [re.findall(r'[a-zA-Z]+',n.text) for n in nat_rows[0:]]\n",
    "list_of_nat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "#### Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display IMDB's top 250 data (movie name, initial release, director name and stars) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = input('Enter the city: ')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the book name, price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
